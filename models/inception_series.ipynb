{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b536cde-b9ec-4fdd-9e21-e43f6784374c",
   "metadata": {},
   "source": [
    ">### Inception Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5957ad9-3da0-4e6d-96ce-237808ee4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9bb3a-4e8f-4e4f-9b24-c1ef3f602c2b",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab4fbed5-403d-452c-8902-982871efaaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label): \n",
    "    image = tf.cast(image, tf.float32) \n",
    "    image = tf.image.resize(image, [299, 299]) #resize前默认图片dim=3\n",
    "    c1 = tf.expand_dims(image[...,0],-1)*(0.229/0.5)+(0.485-0.5)/0.5\n",
    "    c2 = tf.expand_dims(image[...,1],-1)*(0.224/0.5)+(0.456-0.5)/0.5\n",
    "    c3 = tf.expand_dims(image[...,2],-1)*(0.225/0.5)+(0.406-0.5)/0.5\n",
    "    image = tf.concat([c1, c2, c3], axis=-1)\n",
    "    image = tf.clip_by_value(image,0,255)\n",
    "    image = image/255\n",
    "    return image, label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66617d26-8b62-4cf2-aa25-71f4f840b285",
   "metadata": {},
   "source": [
    "#### InceptionV1\n",
    "Paper: [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1000/1*KnTe9YGNopUMiRjlEr3b8w.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0b4e1-94a3-433d-91c2-33b9f2bcf8f2",
   "metadata": {},
   "source": [
    "#### InceptionV3\n",
    "Paper: [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1000/1*ooVUXW6BIcoRdsF7kzkMwQ.png'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8e42dcad-a5c9-45b2-af29-c233a54a2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='valid', zeros=None): \n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.zeros = zeros\n",
    "        if self.zeros:\n",
    "            self.p = layers.ZeroPadding2D(zeros)\n",
    "        self.conv = layers.Conv2D(filters, kernel_size, strides, padding=padding) \n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu') \n",
    "        \n",
    "    def call(self, x):\n",
    "        if self.zeros:\n",
    "            x = self.p(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "544b406f-cea2-4817-b12a-92050780462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#不做下采样 (w,h)->(w,h)\n",
    "class InceptionA(keras.Model): \n",
    "    def __init__(self, pool_features): \n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = ConvBlock(64, 1)\n",
    "        self.branch5x5_1 = ConvBlock(48, 1)\n",
    "        self.branch5x5_2 = ConvBlock(64, 5, padding='same')\n",
    "        self.branch3x3dbl_1 = ConvBlock(64, 1)\n",
    "        self.branch3x3dbl_2 = ConvBlock(96, 3, padding='same')\n",
    "        self.branch3x3dbl_3 = ConvBlock(96, 3, padding='same')\n",
    "        self.branch_pool_1 = layers.AvgPool2D(3, 1, padding='same')\n",
    "        self.branch_pool_2 = ConvBlock(pool_features, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_1(x)\n",
    "        branch_pool = self.branch_pool_2(branch_pool)\n",
    "\n",
    "        outputs = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool])\n",
    "        return outputs\n",
    "\n",
    "        \n",
    "class InceptionB(keras.Model):\n",
    "    def __init__(self, c7): \n",
    "        super(InceptionB, self).__init__()\n",
    "        self.branch1x1 = ConvBlock(192, 1)\n",
    "        self.branch7x7_1 = ConvBlock(c7, 1)\n",
    "        self.branch7x7_2 = ConvBlock(c7, (1,7), zeros=(0,3))\n",
    "        self.branch7x7_3 = ConvBlock(192, (7,1), zeros=(3,0))\n",
    "        self.branch7x7dbl_1 = ConvBlock(c7, 1)\n",
    "        self.branch7x7dbl_2 = ConvBlock(c7, (7,1), zeros=(3,0))\n",
    "        self.branch7x7dbl_3 = ConvBlock(c7, (1,7), zeros=(0,3))\n",
    "        self.branch7x7dbl_4 = ConvBlock(c7, (7,1), zeros=(3,0))\n",
    "        self.branch7x7dbl_5 = ConvBlock(192, (1,7), zeros=(0,3))\n",
    "        self.branch_pool_1 = layers.AvgPool2D(3, 1, padding='same')\n",
    "        self.branch_pool_2 = ConvBlock(192, 1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_1(x)\n",
    "        branch_pool = self.branch_pool_2(branch_pool)\n",
    "\n",
    "        outputs = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool])\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "class InceptionC(keras.Model): \n",
    "    def __init__(self): \n",
    "        super(InceptionC, self).__init__()\n",
    "        self.branch1x1 = ConvBlock(320, 1)\n",
    "        self.branch3x3_1 = ConvBlock(384, 1)\n",
    "        self.branch3x3_2a = ConvBlock(384, (1,3), zeros=(0,1))\n",
    "        self.branch3x3_2b = ConvBlock(384, (3,1), zeros=(1,0))\n",
    "        self.branch3x3dbl_1 = ConvBlock(448, 1)\n",
    "        self.branch3x3dbl_2 = ConvBlock(384, 3, padding='same')\n",
    "        self.branch3x3dbl_3a = ConvBlock(384, (1,3), zeros=(0,1))\n",
    "        self.branch3x3dbl_3b = ConvBlock(384, (3,1), zeros=(1,0))\n",
    "        self.branch_pool_1 = layers.AvgPool2D(3, 1, padding='same')\n",
    "        self.branch_pool_2 = ConvBlock(192, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = layers.concatenate([self.branch3x3_2a(branch3x3),\n",
    "                                        self.branch3x3_2b(branch3x3)])\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = layers.concatenate([self.branch3x3dbl_3a(branch3x3dbl),\n",
    "                                           self.branch3x3dbl_3b(branch3x3dbl)])\n",
    "                                          \n",
    "        branch_pool = self.branch_pool_1(x)\n",
    "        branch_pool = self.branch_pool_2(branch_pool)\n",
    "\n",
    "        outputs = layers.concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool])\n",
    "        return outputs                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "2424f437-4ed0-410d-aea4-0cd48c669a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#下采样 \n",
    "class ReductionA(keras.Model):\n",
    "    def __init__(self): \n",
    "        super(ReductionA, self).__init__()\n",
    "        self.branch3x3 = ConvBlock(384, 3, 2)\n",
    "        self.branch3x3dbl_1 = ConvBlock(64, 1)\n",
    "        self.branch3x3dbl_2 = ConvBlock(96, 3, padding='same')\n",
    "        self.branch3x3dbl_3 = ConvBlock(96, 3, 2)\n",
    "        self.branch_pool_1 = layers.MaxPooling2D(3, 2)\n",
    "\n",
    "    def call(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "        \n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_1(x)\n",
    "        \n",
    "        outputs = layers.concatenate([branch3x3, branch3x3dbl, branch_pool])\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "class ReductionB(keras.Model):\n",
    "    def __init__(self): \n",
    "        super(ReductionB, self).__init__()\n",
    "        self.branch3x3_1 = ConvBlock(192, 1)\n",
    "        self.branch3x3_2 = ConvBlock(320, 3, 2)\n",
    "        self.branch7x7x3_1 = ConvBlock(192, 1)\n",
    "        self.branch7x7x3_2 = ConvBlock(192, (1,7), zeros=(0,3))\n",
    "        self.branch7x7x3_3 = ConvBlock(192, (7,1), zeros=(3,0))\n",
    "        self.branch7x7x3_4 = ConvBlock(192, 3, 2)\n",
    "        self.branch_pool = layers.MaxPooling2D(3, 2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = self.branch_pool(x)\n",
    "        outputs = layers.concatenate([branch3x3, branch7x7x3, branch_pool])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "86caf00c-57a1-488d-9906-418b35410281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionAux(keras.Model):\n",
    "    def __init__(self, num_classes): \n",
    "        super(InceptionAux, self).__init__()\n",
    "        self.pool = layers.AvgPool2D(5, 3)\n",
    "        self.conv0 = ConvBlock(128, 1)\n",
    "        self.conv1 = ConvBlock(768, 5)\n",
    "        #gap的话默认输出(1,1)并且压缩只剩下c，而自适应可以自定义output size\n",
    "        self.adaptive = tfa.layers.AdaptiveAveragePooling2D((1,1)) \n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x): #(b,17,17,768)\n",
    "        x = self.pool(x) \n",
    "        x = self.conv0(x) \n",
    "        x = self.conv1(x)\n",
    "        x = self.adaptive(x) #(b,1,1,768)\n",
    "        x = self.flatten(x)\n",
    "        outputs = self.fc(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "eddca44a-d338-468a-abc2-57b3c6f6c1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 299, 299, 234) dtype=float32 (created by layer 'concatenate_15')>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_a_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_block_549 (ConvBlock)   (None, 299, 299, 64)      512       \n",
      "_________________________________________________________________\n",
      "conv_block_550 (ConvBlock)   (None, 299, 299, 48)      384       \n",
      "_________________________________________________________________\n",
      "conv_block_551 (ConvBlock)   (None, 299, 299, 64)      77120     \n",
      "_________________________________________________________________\n",
      "conv_block_552 (ConvBlock)   (None, 299, 299, 64)      512       \n",
      "_________________________________________________________________\n",
      "conv_block_553 (ConvBlock)   (None, 299, 299, 96)      55776     \n",
      "_________________________________________________________________\n",
      "conv_block_554 (ConvBlock)   (None, 299, 299, 96)      83424     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_94 (Averag (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv_block_555 (ConvBlock)   (None, 299, 299, 10)      80        \n",
      "=================================================================\n",
      "Total params: 217,808\n",
      "Trainable params: 216,924\n",
      "Non-trainable params: 884\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 检查blocks\n",
    "inputs = keras.Input(shape=(299,299,3))\n",
    "model = InceptionA(10)\n",
    "model.build(input_shape=(None,299,299,3))\n",
    "model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "5fa797fb-71a9-470a-b812-c5c3509cb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(keras.Model):\n",
    "    def __init__(self, num_classes=1000, aux_logits=True): \n",
    "        super(InceptionV3, self).__init__(name='inceptionv3')\n",
    "        self.aux_logits = aux_logits\n",
    "        # Stem\n",
    "        self.Conv2d_1a_3x3 = ConvBlock(32, 3, 2)\n",
    "        self.Conv2d_2a_3x3 = ConvBlock(32, 3)\n",
    "        self.Conv2d_2b_3x3 = ConvBlock(64, 3, padding='same')\n",
    "        self.maxpool1 = layers.MaxPooling2D(3, 2)\n",
    "        self.Conv2d_3b_1x1 = ConvBlock(80, 1)\n",
    "        self.Conv2d_4a_3x3 = ConvBlock(192, 3)\n",
    "        self.maxpool2 = layers.MaxPooling2D(3, 2)\n",
    "        \n",
    "        # Inception modules\n",
    "        self.Mixed_5b = InceptionA(32)\n",
    "        self.Mixed_5c = InceptionA(64)\n",
    "        self.Mixed_5d = InceptionA(64)\n",
    "        self.Mixed_6a = ReductionA()\n",
    "        self.Mixed_6b = InceptionB(128)\n",
    "        self.Mixed_6c = InceptionB(160)\n",
    "        self.Mixed_6d = InceptionB(160)\n",
    "        self.Mixed_6e = InceptionB(192)\n",
    "\n",
    "        if self.aux_logits: # Auxiliary classifier\n",
    "            self.AuxLogits = InceptionAux(num_classes)\n",
    "        self.Mixed_7a = ReductionB()\n",
    "        self.Mixed_7b = InceptionC()\n",
    "        self.Mixed_7c = InceptionC()\n",
    "        self.avgpool = tfa.layers.AdaptiveAveragePooling2D((1,1))\n",
    "        self.dropout = layers.Dropout(0.3)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "        \n",
    "    def call(self, x, training=False): #(b, 299, 299, 3)\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.Mixed_5b(x)\n",
    "        x = self.Mixed_5c(x)\n",
    "        x = self.Mixed_5d(x)\n",
    "        x = self.Mixed_6a(x)\n",
    "        x = self.Mixed_6b(x)\n",
    "        x = self.Mixed_6c(x)\n",
    "        x = self.Mixed_6d(x)\n",
    "        x = self.Mixed_6e(x)\n",
    "        \n",
    "        #只在训练时候使用，model.fit时自动调整为True，预测不用\n",
    "        if training and self.aux_logits:\n",
    "            aux = self.AuxLogits(x)\n",
    "        else:\n",
    "            aux = None\n",
    "        \n",
    "        x = self.Mixed_7a(x)\n",
    "        x = self.Mixed_7b(x)\n",
    "        x = self.Mixed_7c(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "77252e83-bb85-4566-9165-aa5d3399b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'dense_68')>,\n",
       " <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'inception_aux_11')>)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inceptionv3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_block_966 (ConvBlock)   (None, 149, 149, 32)      1024      \n",
      "_________________________________________________________________\n",
      "conv_block_967 (ConvBlock)   (None, 147, 147, 32)      9376      \n",
      "_________________________________________________________________\n",
      "conv_block_968 (ConvBlock)   (None, 147, 147, 64)      18752     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_block_969 (ConvBlock)   (None, 73, 73, 80)        5520      \n",
      "_________________________________________________________________\n",
      "conv_block_970 (ConvBlock)   (None, 71, 71, 192)       139200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 35, 35, 192)       0         \n",
      "_________________________________________________________________\n",
      "inception_a_35 (InceptionA)  (None, 35, 35, 256)       257296    \n",
      "_________________________________________________________________\n",
      "inception_a_36 (InceptionA)  (None, 35, 35, 288)       278960    \n",
      "_________________________________________________________________\n",
      "inception_a_37 (InceptionA)  (None, 35, 35, 288)       286640    \n",
      "_________________________________________________________________\n",
      "reduction_a_4 (ReductionA)   (None, 17, 17, 768)       1155200   \n",
      "_________________________________________________________________\n",
      "inception_b_22 (InceptionB)  (None, 17, 17, 768)       1302016   \n",
      "_________________________________________________________________\n",
      "inception_b_23 (InceptionB)  (None, 17, 17, 768)       1696192   \n",
      "_________________________________________________________________\n",
      "inception_b_24 (InceptionB)  (None, 17, 17, 768)       1696192   \n",
      "_________________________________________________________________\n",
      "inception_b_25 (InceptionB)  (None, 17, 17, 768)       2147712   \n",
      "_________________________________________________________________\n",
      "inception_aux_11 (InceptionA (None, 1000)              3329384   \n",
      "_________________________________________________________________\n",
      "reduction_b_4 (ReductionB)   (None, 8, 8, 1280)        1702144   \n",
      "_________________________________________________________________\n",
      "inception_c_31 (InceptionC)  (None, 8, 8, 2048)        5054400   \n",
      "_________________________________________________________________\n",
      "inception_c_32 (InceptionC)  (None, 8, 8, 2048)        6086592   \n",
      "_________________________________________________________________\n",
      "adaptive_average_pooling2d_2 (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1000)              2049000   \n",
      "=================================================================\n",
      "Total params: 27,215,600\n",
      "Trainable params: 27,179,376\n",
      "Non-trainable params: 36,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(299,299,3))\n",
    "model = InceptionV3()\n",
    "model.build(input_shape=(None,299,299,3))\n",
    "model.call(inputs, training=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a860bec2-7d21-4af0-b655-edfcadda2b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - 31s 32ms/step - loss: 0.9166 - accuracy: 0.7087 - val_loss: 0.2903 - val_accuracy: 0.9144\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - 32s 34ms/step - loss: 0.2362 - accuracy: 0.9287 - val_loss: 0.1853 - val_accuracy: 0.9423\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - 32s 34ms/step - loss: 0.1580 - accuracy: 0.9517 - val_loss: 0.1220 - val_accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train, validation_data=test, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678274-42b4-4b24-b3ee-a71755c88482",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### InceptionV4\n",
    "Paper: [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1000/1*15sIUNOxqVyDPmGGqefyVw.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f39fdc-a4b9-479f-8f87-b2043904b4e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inception ResNet\n",
    "Paper: [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1000/1*xpb6QFQ4IknSmxmgai8w-Q.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68a0c5-ff5e-4cbf-b112-fcc27857d1f3",
   "metadata": {},
   "source": [
    "#### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ae6cad5e-d311-4fd4-a1e0-07651ddb70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3, InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c720323d-e710-48ef-a06a-bca97686e4cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 149, 149, 32) 864         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 149, 149, 32) 96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 149, 149, 32) 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 147, 147, 32) 9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 147, 147, 32) 96          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 147, 147, 32) 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 147, 147, 64) 18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 147, 147, 64) 192         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 147, 147, 64) 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 73, 73, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 73, 73, 80)   240         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 73, 73, 80)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 71, 71, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 71, 71, 192)  576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 71, 71, 192)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 35, 35, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 35, 35, 64)   192         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 35, 35, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 35, 35, 48)   144         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 35, 35, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 35, 35, 48)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 35, 35, 96)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 35, 35, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 35, 35, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 35, 35, 64)   192         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 35, 35, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 35, 35, 96)   288         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 35, 35, 32)   96          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 35, 35, 64)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 35, 35, 64)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 35, 35, 32)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 35, 35, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 35, 35, 48)   144         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 35, 35, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 35, 35, 48)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 35, 35, 96)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 35, 35, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 35, 35, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 35, 35, 64)   192         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 35, 35, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 35, 35, 96)   288         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 35, 35, 64)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 35, 35, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 35, 35, 64)   192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 35, 35, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 35, 35, 48)   144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 35, 35, 48)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 35, 35, 96)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 35, 35, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 35, 35, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 35, 35, 64)   192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 35, 35, 96)   288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 35, 35, 64)   192         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 35, 35, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 35, 35, 64)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 35, 35, 64)   192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 35, 35, 64)   0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 35, 35, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 35, 35, 96)   288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 35, 35, 96)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 17, 17, 96)   82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 17, 17, 384)  1152        conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 17, 17, 96)   288         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 17, 17, 384)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 17, 17, 96)   0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 17, 17, 128)  384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 17, 17, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 17, 17, 128)  114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 17, 17, 128)  384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 17, 17, 128)  384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 17, 17, 128)  114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 17, 17, 128)  384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 17, 17, 192)  172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 17, 17, 192)  172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 17, 17, 192)  576         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 17, 17, 192)  576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 17, 17, 192)  576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 17, 17, 192)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 17, 17, 192)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 17, 17, 160)  480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 17, 17, 160)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 17, 17, 160)  179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 17, 17, 160)  480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 17, 17, 160)  179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 17, 17, 160)  480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 17, 17, 192)  215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 17, 17, 192)  215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 17, 17, 192)  576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 17, 17, 192)  576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 17, 17, 192)  576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 17, 17, 192)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 17, 17, 160)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 17, 17, 160)  179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 17, 17, 160)  179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 17, 17, 160)  480         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 17, 17, 192)  215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 17, 17, 192)  215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 17, 17, 192)  576         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 17, 17, 192)  576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 17, 17, 192)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 17, 17, 192)  258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 17, 17, 192)  258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 17, 17, 192)  0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 17, 17, 192)  258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 17, 17, 192)  576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 17, 17, 192)  576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 8, 8, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 8, 8, 320)    960         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 8, 8, 192)    576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 8, 8, 320)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 448)    1344        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 8, 8, 448)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 8, 8, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 8, 8, 384)    1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 384)    1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 8, 8, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 384)    1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 8, 8, 320)    960         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 192)    576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 8, 8, 320)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 192)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 448)    1344        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 448)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 8, 8, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 8, 8, 384)    1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 384)    1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 8, 8, 384)    1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 8, 8, 384)    1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 320)    960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 8, 8, 192)    576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 320)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 8, 8, 192)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3(input_shape=(299,299,3), include_top=True,\n",
    "                    weights=None, classes=1000) \n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

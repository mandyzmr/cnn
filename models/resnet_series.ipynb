{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5edc7f-0a2a-48e3-96b5-d3b1537b074a",
   "metadata": {},
   "source": [
    "> ### ResNet\n",
    "\n",
    "ResNet adds a shortcut to the main path through the network. By stacking these ResNet blocks on top of each other, you can form a very deep network. \n",
    "\n",
    "- Easy for one of the blocks to learn an identity function with little risk of harming training set performance.  \n",
    "- Skip connections helps with vanishing gradients.\n",
    "\n",
    "Depending mainly on whether the input/output dimensions are same or different, there are two main blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7889eaba-1981-4be9-aa46-f9886ad53791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b395cf-e3b8-4883-aa9a-5e5d039f9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed02fb-5fda-4cfa-b7df-fc41c8a02c9c",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f80991-194b-43b7-afb6-073f6c480487",
   "metadata": {},
   "source": [
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39248fa0-ceb7-480e-ac03-7ee1d6517d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "from resnets_utils import *\n",
    "X_train_orig, y_train_orig, X_test_orig, y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "y_train = convert_to_one_hot(y_train_orig, 6).T\n",
    "y_test = convert_to_one_hot(y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6fb465-474e-488f-9b05-3bcee29efdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d60a62-2cae-4e89-84a8-10cc18d172d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ResNet50\n",
    "Paper: [Deep Residual Learning for Image Recognitio](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1000/1*zbDxCB-0QDAc4oUGVtg3xw.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698de984-952a-4182-83ee-e53aa1514fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Identity Block**\n",
    "- $a^{[l]}$ has the same dimension as $a^{[l+2]}$ \n",
    "- $W_s$ is a learned parameter used to resize the input $a^{[l]}$ to match main path. \n",
    "\n",
    "**Convolutional Block**\n",
    "* $a^{[l]}$ has different dimension as $a^{[l+2]}$ \n",
    "* The CONV2D layer in the shortcut path is a learned linear function used to resize the input $x$ to a different dimension, to match main path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0899cb6b-a297-42fb-96b3-8ff739d6738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 适用于ResNet18,34\n",
    "class BasicBlock(keras.Model):\n",
    "    expansion=1 #为了和Bottleneck保持一致，方便引用，要写成global变量才能在不用实例化之前直接引用\n",
    "    def __init__(self, filters, strides, kernel_size=3, downsampling=False, dilation_rate=1): \n",
    "        super(BasicBlock, self).__init__()\n",
    "        #第一层stride有时候需要downsample，而第二层stride默认1\n",
    "        #tf的padding神奇在于，选择same和stride=2时，相当于减半而非不变\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size, strides, padding='same', #由于后面加bn，可以设置use_bias=False，因为会抵消掉\n",
    "                                  dilation_rate=dilation_rate) #可以增加dilation_rate做空洞卷积\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(filters*BasicBlock.expansion, kernel_size, strides=1, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu') #可以重复使用，因为只是个函数，没有weights\n",
    "        self.add = layers.Add()\n",
    "        \n",
    "        #当downsampling时，需要用ConvBlock，没有relu\n",
    "        if downsampling:\n",
    "            self.shortcut = keras.Sequential([\n",
    "                layers.Conv2D(filters*BasicBlock.expansion, 1, strides),\n",
    "                layers.BatchNormalization()])\n",
    "        else:\n",
    "            self.shortcut = lambda x:x\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x) \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.add([x, self.shortcut(inputs)])\n",
    "        x = self.relu(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3acbc8f-72d4-4a4f-b688-98c65bdb99f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 112, 112, 64) dtype=float32 (created by layer 'activation_128')>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_block_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_377 (Conv2D)          (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_379 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_378 (Conv2D)          (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_380 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "add_123 (Add)                (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "sequential_45 (Sequential)   (None, 112, 112, 64)      512       \n",
      "=================================================================\n",
      "Total params: 39,744\n",
      "Trainable params: 39,360\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(224,224,3))\n",
    "model = BasicBlock(64,2,downsampling=True)\n",
    "model.build(input_shape=(None,224,224,3))\n",
    "model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5eac9d2-cb32-4ab0-8252-7180034d999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 适用于ResNet50,101,152\n",
    "class BottleNeck(keras.Model):\n",
    "    expansion = 4\n",
    "    def __init__(self, filters, strides, kernel_size=3, downsampling=False, dilation_rate=1): \n",
    "        super(BottleNeck, self).__init__()\n",
    "        #瓶颈 feature map\n",
    "        self.conv1 = layers.Conv2D(filters, 1, strides=1, padding='same') #降c\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size, strides, padding='same', #降hw\n",
    "                                   dilation_rate=dilation_rate) #可以增加空洞卷积，对应strides=1\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(filters*BottleNeck.expansion, 1, strides=1, padding='same') #增c\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.add = layers.Add()\n",
    "       \n",
    "        #当downsampling时，需要用ConvBlock\n",
    "        if downsampling:\n",
    "            self.shortcut = keras.Sequential([\n",
    "                layers.Conv2D(filters*BottleNeck.expansion, 1, strides),\n",
    "                layers.BatchNormalization()])\n",
    "        else:\n",
    "            self.shortcut = lambda x:x\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x) \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x) \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.add([x, self.shortcut(inputs)])\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b51fea1-4777-49be-8fed-9409b95ad93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 112, 112, 256) dtype=float32 (created by layer 'activation_2')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bottle_neck_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 256)     16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 112, 112, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 112, 112, 256)     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 112, 112, 256)     2048      \n",
      "=================================================================\n",
      "Total params: 57,408\n",
      "Trainable params: 56,128\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(224,224,3))\n",
    "model = BottleNeck(64,2, downsampling=True)\n",
    "model.build(input_shape=(None,224,224,3))\n",
    "model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ccbc5-9db5-49b0-add6-86ba1fe3cfc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"images/resnet_structure.jpg\" style=\"width:600px;height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "294ccf7e-0a3d-44bd-9947-6b75a00d0b66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(keras.Model):    \n",
    "    def __init__(self, name, block=None, n_blocks=None, num_classes=10, \n",
    "                 dilation_rate=[1,1,1], #若增加空洞卷积，layer 5直接指定每个block的d\n",
    "                 os=16): #output_stride 可选下采样倍数os=8/16，传统resnet都是2**5=32倍downsampling\n",
    "        super(ResNet, self).__init__(name=name) \n",
    "       \n",
    "        # 结构：使用自定义的结构，或者经典结构\n",
    "        self.structure = name\n",
    "        self.block = block #用basicblock还是bottleneck\n",
    "        self.n_blocks = n_blocks #每个block循环次数\n",
    "        self.num_classes = num_classes \n",
    "        self.get_structure() #重新整理结构\n",
    "    \n",
    "        # Stem \n",
    "        self.layer1 = keras.Sequential(\n",
    "            [layers.ZeroPadding2D(3), #由于Conv2D内无法自定义padding=3，需要先另外做padding \n",
    "             layers.Conv2D(64, 7, 2), #2倍downsample\n",
    "             layers.BatchNormalization(), \n",
    "             layers.Activation('relu'), \n",
    "             layers.MaxPool2D(3, 2, padding='same')]) #4倍downsample\n",
    "        \n",
    "        if os==16 and dilation_rate==[1,1,1]: #代表用传统的32倍downsample，不用空洞卷积\n",
    "            strides=[1,2,2,2]\n",
    "        elif os==16: #若16倍downsample，仅最后layer 5 strides=1\n",
    "            strides=[1,2,2,1] \n",
    "        elif os==8: #若8倍downsample，最后layer 4-5 strides=1\n",
    "            strides=[1,2,1,1] \n",
    "            \n",
    "        #除了layer2因为有事先pooling降维之外，其余layer都是第一个block的stride=2降维，其余blocks的stride=1\n",
    "        self.layer2 = self.build_blocks(64, self.n_blocks[0], strides=strides[0])         \n",
    "        self.layer3 = self.build_blocks(128, self.n_blocks[1], strides=strides[1]) #8倍downsample，根据下面layers决定最终downsample倍数   \n",
    "        self.layer4 = self.build_blocks(256, self.n_blocks[2], strides=strides[2], \n",
    "                                        dilation_rate=16//os) #可以对每个block做空洞d，因为不同resnet结构layer4的n_blocks不同，在函数另外构造d列表     \n",
    "        self.layer5 = self.build_blocks(512, self.n_blocks[3], strides=strides[3], \n",
    "                                        #dilation_rate=dilation_rate) #由于layer5统一都是3个blocks，直接指定每个block的空洞d，如[1,2,1]\n",
    "                                        dilation_rate=[i*16//os for i in dilation_rate]) #若下采样os=8倍为止，那么这层的dilated_rate要乘以2\n",
    "        \n",
    "        #如果没有classes，则不返回classifier部分，可以把resnet用作其他模型的backbone结构\n",
    "        if self.num_classes:\n",
    "            self.avgpool = layers.GlobalAveragePooling2D()  # 降为1x1xc        \n",
    "            self.fc = layers.Dense(self.num_classes, activation='softmax') \n",
    "    \n",
    "    \n",
    "    def get_structure(self):\n",
    "        versions = {'resnet18':(BasicBlock,[2,2,2,2]), \n",
    "                     'resnet34':(BasicBlock,[3,4,6,3]),\n",
    "                     'resnet50':(BottleNeck,[3,4,6,3]),\n",
    "                     'resnet101':(BottleNeck,[3,4,23,3]),\n",
    "                     'resnet152':(BottleNeck,[3,8,36,3])}\n",
    "        \n",
    "        if not self.block or not self.n_blocks: #如果任意一项没有定义\n",
    "            self.block, self.n_blocks = versions[self.structure]\n",
    "        \n",
    "        \n",
    "    def build_blocks(self, filters, n_blocks, strides, dilation_rate=1):\n",
    "        if isinstance(dilation_rate, int): #根据具体blocks数构造\n",
    "            dilation_rate=[dilation_rate]*n_blocks\n",
    "            \n",
    "        res_blocks = keras.Sequential() \n",
    "        res_blocks.add(self.block(filters, strides, downsampling=True, dilation_rate=dilation_rate[0])) \n",
    "        for i in range(1, n_blocks): #跳过第一个block            \n",
    "            res_blocks.add(self.block(filters, strides=1, dilation_rate=dilation_rate[i])) \n",
    "        return res_blocks\n",
    " \n",
    "\n",
    "    def call(self, inputs): \n",
    "        x = self.layer1(inputs)  \n",
    "        x = self.layer2(x)         \n",
    "        x = self.layer3(x)         \n",
    "        x = self.layer4(x)         \n",
    "        x = self.layer5(x) \n",
    "        \n",
    "        if self.num_classes: \n",
    "            x = self.avgpool(x)          \n",
    "            x = self.fc(x)     \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf6c97ce-50d6-4b2d-99fc-adc5a29ca7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 14, 14, 2048) dtype=float32 (created by layer 'sequential_43')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_36 (Sequential)   (None, 56, 56, 64)        9728      \n",
      "_________________________________________________________________\n",
      "sequential_37 (Sequential)   (None, 56, 56, 256)       220032    \n",
      "_________________________________________________________________\n",
      "sequential_39 (Sequential)   (None, 28, 28, 512)       1230336   \n",
      "_________________________________________________________________\n",
      "sequential_41 (Sequential)   (None, 14, 14, 1024)      7129088   \n",
      "_________________________________________________________________\n",
      "sequential_43 (Sequential)   (None, 14, 14, 2048)      14998528  \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(224,224,3))\n",
    "model = ResNet('resnet50', num_classes=None, dilation_rate=[1,2,1], os=16)\n",
    "model.build(input_shape=(None,224,224,3))\n",
    "model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f49a7958-9ddf-46c0-92d3-07f32d2572d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.3194 - accuracy: 0.9000\n",
      "Epoch 2/3\n",
      "34/34 [==============================] - 118s 3s/step - loss: 0.2371 - accuracy: 0.9269\n",
      "Epoch 3/3\n",
      "34/34 [==============================] - 143s 4s/step - loss: 0.2737 - accuracy: 0.9120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a4782b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 479ms/step - loss: 0.6055 - accuracy: 0.8250\n",
      "Loss = 0.6055490970611572\n",
      "Test Accuracy = 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs = 3, batch_size = 32, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63c681-eb6f-48f5-b78e-d9b4cbb9928a",
   "metadata": {},
   "source": [
    "#### ResNeXt-50\n",
    "Paper: [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1000/1*HelCJiQZEuwuKakRwDdGPw.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc878c-5366-4dd1-a206-067eafb631c2",
   "metadata": {},
   "source": [
    "#### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90636838-2f83-423d-b8f1-d39ccd372587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, ResNet101, ResNet152 #都有version2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "584299b4-b58e-48ee-b486-ec0ebc026fe9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (224,224,3), include_top=True, \n",
    "              weights=None, classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f415d1b-1e2f-48a8-8989-f6fa289e839d",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60e66c52-9d4b-4ffb-b731-2980e046b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x149ef1880>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)]:\n",
      "[[3.4187831e-06 2.7741338e-04 9.9952292e-01 1.9884338e-07 1.9561945e-04\n",
      "  4.1168707e-07]]\n",
      "Class: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "print('Input image shape:', x.shape)\n",
    "plt.imshow(img)\n",
    "prediction = model.predict(x)\n",
    "print(f\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)]:\\n{prediction}\")\n",
    "print(\"Class:\", np.argmax(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
